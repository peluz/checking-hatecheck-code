{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbceb8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from ray import tune\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import initialize_seeds\n",
    "from data_utils import HateDataset, get_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058a6efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4b1161",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6774cc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./hatecheck-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08996e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_df = pd.read_csv(data_path/\"test_suite_cases.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a445c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_df.label_gold.replace({'hateful': 1, 'non-hateful': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b175a",
   "metadata": {},
   "source": [
    "## Stratified sampling with held-out rules and groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470f4bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_df.groupby(\"label_gold\")[\"functionality\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901e9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_nonhate_funcs = random.sample(pd.unique(hatecheck_df[hatecheck_df[\"label_gold\"]==0][\"functionality\"]).tolist(),2); heldout_nonhate_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c69a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_hate_funcs = random.sample(pd.unique(hatecheck_df[hatecheck_df[\"label_gold\"]==1][\"functionality\"]).tolist(),3); heldout_hate_funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4031522",
   "metadata": {},
   "outputs": [],
   "source": [
    "heldout_idents = random.sample(pd.unique(hatecheck_df[\"target_ident\"].dropna()).tolist(),2); heldout_idents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6711f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "held_out_dic = {}\n",
    "held_out_dic[\"hateful_funcs\"] = heldout_hate_funcs\n",
    "held_out_dic[\"nonhateful_funcs\"] = heldout_nonhate_funcs\n",
    "held_out_dic[\"idents\"] = heldout_idents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5111559c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/held_out_dic.pkl\", \"wb\") as file:\n",
    "    pickle.dump(held_out_dic, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712c90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_seen = hatecheck_df[~(hatecheck_df[\"functionality\"].isin(heldout_hate_funcs + heldout_nonhate_funcs) |\n",
    "                                hatecheck_df[\"target_ident\"].isin(heldout_idents))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8fd696",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ((hatecheck_seen[\"functionality\"].isin(heldout_hate_funcs + heldout_nonhate_funcs)).sum() + \n",
    "         hatecheck_seen[\"target_ident\"].isin(heldout_idents).sum()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9949e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_unseen = hatecheck_df[(hatecheck_df[\"functionality\"].isin(heldout_hate_funcs + heldout_nonhate_funcs) |\n",
    "                                hatecheck_df[\"target_ident\"].isin(heldout_idents))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0023a17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_unseen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb0108",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(hatecheck_seen) + len(hatecheck_unseen) == len(hatecheck_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84a6718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valtest = train_test_split(hatecheck_seen, test_size=0.2, stratify=hatecheck_seen.label_gold, random_state=42)\n",
    "df_valtest = pd.concat([df_valtest, hatecheck_unseen])\n",
    "df_val, df_test = train_test_split(df_valtest, test_size=0.5, stratify=df_valtest.label_gold, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc351978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label_gold.value_counts(), df_val.label_gold.value_counts(), df_test.label_gold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9984b850",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test_cases = len(df_val) + len(df_test); n_test_cases, n_test_cases/len(hatecheck_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0415bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(df_train) + len(df_val) + len(df_test) == len(hatecheck_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d0620a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = df_train.test_case.astype(\"string\").tolist()\n",
    "val_texts = df_val.test_case.astype(\"string\").tolist()\n",
    "test_texts = df_test.test_case.astype(\"string\").tolist()\n",
    "    \n",
    "train_labels = df_train.label_gold.tolist()\n",
    "val_labels = df_val.label_gold.tolist()\n",
    "test_labels = df_test.label_gold.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec00959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes = np.unique(train_labels), y = train_labels); class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1123ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizerFast.from_pretrained(\"BERT_davidson2017_weighted/Final\")\n",
    "if DEV:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('prajjwal1/bert-tiny')\n",
    "else:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "num_added_toks = tokenizer.add_special_tokens({'additional_special_tokens': ['[USER]','[EMOJI]','[URL]']}); num_added_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f8f5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text series\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5323ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HateDataset(train_encodings, train_labels)\n",
    "val_dataset = HateDataset(val_encodings, val_labels)\n",
    "test_dataset = HateDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d72cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, \"data/unseenSplit_train_hatecheck.pt\")\n",
    "torch.save(val_dataset, \"data/unseenSplit_val_hatecheck.pt\")\n",
    "torch.save(test_dataset, \"data/unseenSplit_test_hatecheck.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5656ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())\n",
    "    print(torch.cuda.device_count(), 'GPUs')\n",
    "else:\n",
    "    print(\"Oops! No GPU found.\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16f14fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    save_steps = 2500,\n",
    "    output_dir=\"./models/BERT_hatecheck_weighted/checkpoints\", # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    evaluation_strategy = 'epoch',\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    learning_rate = 5e-5,\n",
    "    seed = 123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62467ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Trainers with weighted loss\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        weighted_loss = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights)).to(device)\n",
    "        return (weighted_loss(logits,labels), outputs) if return_outputs else weighted_loss(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70710a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define explicit model initialisation to allow for hyperparameter search\n",
    "def model_init():\n",
    "    if DEV:\n",
    "        model = BertForSequenceClassification.from_pretrained(\"prajjwal1/bert-tiny\")\n",
    "    else:\n",
    "        model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "    # resize to match tokenizer length with special tokens added above\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9cd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate weighted trainer objects\n",
    "\n",
    "trainer = WeightedTrainer(                       \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset,            \n",
    "    model_init = model_init\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3303e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform hyperparameter tuning using grid search\n",
    "def custom_hp_space(trial):\n",
    "    if DEV:\n",
    "        return {\n",
    "        \"learning_rate\": tune.grid_search([2e-5, 3e-5, 5e-5]),\n",
    "        \"num_train_epochs\": tune.grid_search([2, 3, 4]),\n",
    "        \"per_device_train_batch_size\": tune.grid_search([4,8])\n",
    "    }\n",
    "    else:\n",
    "        return {\n",
    "            \"learning_rate\": tune.grid_search([2e-5, 3e-5, 5e-5]),\n",
    "            \"num_train_epochs\": tune.grid_search([2, 3, 4]),\n",
    "            \"per_device_train_batch_size\": tune.grid_search([16,32])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e85c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(\n",
    "    backend = 'ray',\n",
    "    hp_space = custom_hp_space,\n",
    "    direction = 'minimize',\n",
    "    n_trials = 1,\n",
    "    progress_reporter = tune.JupyterNotebookReporter(overwrite=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3f9a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fcfa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "        setattr(trainer.args, n, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f555ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d0ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEV:\n",
    "    trainer.save_model('./models/BERT_hateCheck_weighted_unseen/dev')\n",
    "    tokenizer.save_pretrained('./models/BERT_hateCheck_weighted_unseen/dev')\n",
    "else:\n",
    "    trainer.save_model('./models/BERT_hateCheck_weighted_unseen/final')\n",
    "    tokenizer.save_pretrained('./models/BERT_hateCheck_weighted_unseen/final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a13da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fine-tuned model\n",
    "\n",
    "if DEV:\n",
    "    model = BertForSequenceClassification.from_pretrained('./models/BERT_hateCheck_weighted_unseen/dev')\n",
    "else:\n",
    "    model = BertForSequenceClassification.from_pretrained('./models/BERT_hateCheck_weighted_unseen/final') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7469b106",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEV:\n",
    "    trainer = Trainer(\n",
    "        model=model,         \n",
    "        args=TrainingArguments(\n",
    "            output_dir=('./models/BERT_hateCheck_weighted_unseen/devTest'),\n",
    "            per_device_eval_batch_size = 64)\n",
    "    )\n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        model=model,         \n",
    "        args=TrainingArguments(\n",
    "            output_dir=('./models/BERT_hateCheck_weighted_unseen/test'),\n",
    "            per_device_eval_batch_size = 64)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865caeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results, train_preds = get_results(trainer, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdce03f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results, val_preds = get_results(trainer, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f86a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results, test_preds = get_results(trainer, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8f04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"preds\"], df_train[\"split\"] = train_preds, \"train\"\n",
    "df_val[\"preds\"], df_val[\"split\"] = val_preds, \"val\"\n",
    "df_test[\"preds\"], df_test[\"split\"] = test_preds, \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8103a1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.concat([df_train, df_val, df_test], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2019116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"preds\"].replace({1: 'hateful', 0: 'non-hateful'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066b86d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9be1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEV:\n",
    "    preds_df.to_pickle('./results/hatecheck/resultsDEV_BERT_weighted_unseen.pkl')\n",
    "else:\n",
    "    preds_df.to_pickle('./results/hatecheck/results_BERT_weighted_unseen.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04adaa14",
   "metadata": {},
   "source": [
    "## Random stratified splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d497b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valtest = train_test_split(hatecheck_df, test_size=n_test_cases, stratify=hatecheck_df.label_gold, random_state=123)\n",
    "df_val, df_test = train_test_split(df_valtest, test_size=0.5, stratify=df_valtest.label_gold, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663c1ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label_gold.value_counts(), df_val.label_gold.value_counts(), df_test.label_gold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = df_train.test_case.astype(\"string\").tolist()\n",
    "val_texts = df_val.test_case.astype(\"string\").tolist()\n",
    "test_texts = df_test.test_case.astype(\"string\").tolist()\n",
    "    \n",
    "train_labels = df_train.label_gold.tolist()\n",
    "val_labels = df_val.label_gold.tolist()\n",
    "test_labels = df_test.label_gold.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617053b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = compute_class_weight('balanced', classes = np.unique(train_labels), y = train_labels); class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe4b314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizerFast.from_pretrained(\"BERT_davidson2017_weighted/Final\")\n",
    "if DEV:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('prajjwal1/bert-tiny')\n",
    "else:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "num_added_toks = tokenizer.add_special_tokens({'additional_special_tokens': ['[USER]','[EMOJI]','[URL]']}); num_added_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959aafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text series\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710b300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HateDataset(train_encodings, train_labels)\n",
    "val_dataset = HateDataset(val_encodings, val_labels)\n",
    "test_dataset = HateDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f21af5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset, \"data/random_train_hatecheck.pt\")\n",
    "torch.save(val_dataset, \"data/random_val_hatecheck.pt\")\n",
    "torch.save(test_dataset, \"data/random_test_hatecheck.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8362ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    save_steps = 2500,\n",
    "    output_dir=\"./models/BERT_hatecheck_weighted/checkpoints\", # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    evaluation_strategy = 'epoch',\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    learning_rate = 5e-5,\n",
    "    seed = 123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622f7e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate weighted trainer objects\n",
    "\n",
    "trainer = WeightedTrainer(                       \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset,            \n",
    "    model_init = model_init\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform hyperparameter tuning using grid search\n",
    "def custom_hp_space(trial):\n",
    "    if DEV:\n",
    "        return {\n",
    "        \"learning_rate\": tune.grid_search([2e-5, 3e-5, 5e-5]),\n",
    "        \"num_train_epochs\": tune.grid_search([2, 3, 4]),\n",
    "        \"per_device_train_batch_size\": tune.grid_search([4,8])\n",
    "    }\n",
    "    else:\n",
    "        return {\n",
    "            \"learning_rate\": tune.grid_search([2e-5, 3e-5, 5e-5]),\n",
    "            \"num_train_epochs\": tune.grid_search([2, 3, 4]),\n",
    "            \"per_device_train_batch_size\": tune.grid_search([16,32])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44698398",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(\n",
    "    backend = 'ray',\n",
    "    hp_space = custom_hp_space,\n",
    "    direction = 'minimize',\n",
    "    n_trials = 1,\n",
    "    progress_reporter = tune.JupyterNotebookReporter(overwrite=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae604c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3580614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "        setattr(trainer.args, n, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95919691",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43afd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEV:\n",
    "    trainer.save_model('./models/BERT_hateCheck_weighted/dev')\n",
    "    tokenizer.save_pretrained('./models/BERT_hateCheck_weighted/dev')\n",
    "else:\n",
    "    trainer.save_model('./models/BERT_hateCheck_weighted/final')\n",
    "    tokenizer.save_pretrained('./models/BERT_hateCheck_weighted/final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e840c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fine-tuned model\n",
    "\n",
    "if DEV:\n",
    "    model = BertForSequenceClassification.from_pretrained('./models/BERT_hateCheck_weighted/dev')\n",
    "else:\n",
    "    model = BertForSequenceClassification.from_pretrained('./models/BERT_hateCheck_weighted/final') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2bd7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEV:\n",
    "    trainer = Trainer(\n",
    "        model=model,         \n",
    "        args=TrainingArguments(\n",
    "            output_dir=('./models/BERT_hateCheck_weighted/devTest'),\n",
    "            per_device_eval_batch_size = 64)\n",
    "    )\n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        model=model,         \n",
    "        args=TrainingArguments(\n",
    "            output_dir=('./models/BERT_hateCheck_weighted/test'),\n",
    "            per_device_eval_batch_size = 64)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef6cc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results, train_preds = get_results(trainer, train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24008717",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results, val_preds = get_results(trainer, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a497b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results, test_preds = get_results(trainer, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa57b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"preds\"], df_train[\"split\"] = train_preds, \"train\"\n",
    "df_val[\"preds\"], df_val[\"split\"] = val_preds, \"val\"\n",
    "df_test[\"preds\"], df_test[\"split\"] = test_preds, \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69411ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.concat([df_train, df_val, df_test], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"preds\"].replace({1: 'hateful', 0: 'non-hateful'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcc64b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9128cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEV:\n",
    "    preds_df.to_pickle('./results/hatecheck/resultsDEV_BERT_weighted.pkl')\n",
    "else:\n",
    "    preds_df.to_pickle('./results/hatecheck/results_BERT_weighted.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085f899c",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73b43ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valtest = train_test_split(hatecheck_df, test_size=n_test_cases, stratify=hatecheck_df.label_gold, random_state=123)\n",
    "df_val, df_test = train_test_split(df_valtest, test_size=0.5, stratify=df_valtest.label_gold, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9deffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.label_gold.value_counts(), df_val.label_gold.value_counts(), df_test.label_gold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_pickle('./hatecheck-experiments/Data/Clean Training Data/training_data_binary.pkl')\n",
    "\n",
    "df_raw = {}\n",
    "\n",
    "# write to dict\n",
    "for dataset in training_data:\n",
    "    df_raw[dataset] = training_data[dataset].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba18250",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_target = {}\n",
    "\n",
    "for dataset in df_raw:\n",
    "    df_train_target[dataset], _ = train_test_split(df_raw[dataset], test_size=0.2, stratify=df_raw[dataset].label, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eef7751",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train), len(df_train_target[\"davidson2017\"]), len(df_train_target[\"founta2018\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b834b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_with_davidson = df_train.test_case.astype(\"string\").tolist() + df_train_target[\"davidson2017\"].text.astype(\"string\").tolist()\n",
    "train_texts_with_founta = df_train.test_case.astype(\"string\").tolist() + df_train_target[\"founta2018\"].text.astype(\"string\").tolist()\n",
    "val_texts = df_val.test_case.astype(\"string\").tolist()\n",
    "test_texts = df_test.test_case.astype(\"string\").tolist()\n",
    "    \n",
    "train_labels_with_davidson = df_train.label_gold.tolist() + df_train_target[\"davidson2017\"].label.tolist()\n",
    "train_labels_with_founta = df_train.label_gold.tolist() + df_train_target[\"founta2018\"].label.tolist()\n",
    "val_labels = df_val.label_gold.tolist()\n",
    "test_labels = df_test.label_gold.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce60bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = BertTokenizerFast.from_pretrained(\"BERT_davidson2017_weighted/Final\")\n",
    "if DEV:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('prajjwal1/bert-tiny')\n",
    "else:\n",
    "    tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "num_added_toks = tokenizer.add_special_tokens({'additional_special_tokens': ['[USER]','[EMOJI]','[URL]']}); num_added_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db13d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text series\n",
    "train_encodings_with_davidson = tokenizer(train_texts_with_davidson, truncation=True, padding=True)\n",
    "train_encodings_with_founta = tokenizer(train_texts_with_founta, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_davidson = compute_class_weight('balanced', classes = np.unique(train_labels_with_davidson), y = train_labels_with_davidson)\n",
    "class_weights_founta = compute_class_weight('balanced', classes = np.unique(train_labels_with_founta), y = train_labels_with_founta)\n",
    "class_weights_davidson, class_weights_founta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97f78fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_with_davidson = HateDataset(train_encodings_with_davidson, train_labels_with_davidson)\n",
    "train_dataset_with_founta = HateDataset(train_encodings_with_founta, train_labels_with_founta)\n",
    "val_dataset = HateDataset(val_encodings, val_labels)\n",
    "test_dataset = HateDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e14db63",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_dataset_with_davidson, \"data/random_train_hatecheck+davidson.pt\")\n",
    "torch.save(train_dataset_with_founta, \"data/random_train_hatecheck+founta.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17084716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    save_steps = 2500,\n",
    "    output_dir=\"./models/BERT_hatecheck_weighted/checkpoints\", # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    evaluation_strategy = 'epoch',\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    learning_rate = 5e-5,\n",
    "    seed = 123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66962c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTrainerDavidson(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        weighted_loss = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights_davidson)).to(device)\n",
    "        return (weighted_loss(logits,labels), outputs) if return_outputs else weighted_loss(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e9872",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedTrainerFounta(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs[0]\n",
    "        weighted_loss = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights_founta)).to(device)\n",
    "        return (weighted_loss(logits,labels), outputs) if return_outputs else weighted_loss(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff96bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate weighted trainer objects\n",
    "\n",
    "trainer = WeightedTrainerDavidson(                       \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset_with_davidson,         \n",
    "    eval_dataset=val_dataset,            \n",
    "    model_init = model_init\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf7c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform hyperparameter tuning using grid search\n",
    "def custom_hp_space(trial):\n",
    "    if DEV:\n",
    "        return {\n",
    "        \"learning_rate\": tune.grid_search([2e-5, 3e-5, 5e-5]),\n",
    "        \"num_train_epochs\": tune.grid_search([2, 3, 4]),\n",
    "        \"per_device_train_batch_size\": tune.grid_search([4,8])\n",
    "    }\n",
    "    else:\n",
    "        return {\n",
    "            \"learning_rate\": tune.grid_search([2e-5, 3e-5, 5e-5]),\n",
    "            \"num_train_epochs\": tune.grid_search([2, 3, 4]),\n",
    "            \"per_device_train_batch_size\": tune.grid_search([16,32])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d795e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(\n",
    "    backend = 'ray',\n",
    "    hp_space = custom_hp_space,\n",
    "    direction = 'minimize',\n",
    "    n_trials = 1,\n",
    "    progress_reporter = tune.JupyterNotebookReporter(overwrite=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbbe44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e4b327",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "        setattr(trainer.args, n, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54feed4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c65519d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./models/BERT_hateCheck+davidson_weighted/final')\n",
    "tokenizer.save_pretrained('./models/BERT_hateCheck+davidson_weighted/final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fe751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('./models/BERT_hateCheck+davidson_weighted/final') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4537ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEV:\n",
    "    trainer = Trainer(\n",
    "        model=model,         \n",
    "        args=TrainingArguments(\n",
    "            output_dir=('./models/BERT_hateCheck_weighted/devTest'),\n",
    "            per_device_eval_batch_size = 64)\n",
    "    )\n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        model=model,         \n",
    "        args=TrainingArguments(\n",
    "            output_dir=('./models/BERT_hateCheck_weighted/test'),\n",
    "            per_device_eval_batch_size = 64)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e862137",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results, train_preds = get_results(trainer, train_dataset_with_davidson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0e53a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results, val_preds = get_results(trainer, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e1c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results, test_preds = get_results(trainer, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71faea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"preds\"], df_train[\"split\"] = train_preds[:len(df_train)], \"train\"\n",
    "df_val[\"preds\"], df_val[\"split\"] = val_preds, \"val\"\n",
    "df_test[\"preds\"], df_test[\"split\"] = test_preds, \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143663f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.concat([df_train, df_val, df_test], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3987f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"preds\"].replace({1: 'hateful', 0: 'non-hateful'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca5c0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcf09bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_pickle('./results/hatecheck/results_BERT_hateCheck+davidson_weighted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c775f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate weighted trainer objects\n",
    "\n",
    "trainer = WeightedTrainerFounta(                       \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset_with_founta,         \n",
    "    eval_dataset=val_dataset,            \n",
    "    model_init = model_init\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed125fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform hyperparameter tuning using grid search\n",
    "def custom_hp_space(trial):\n",
    "    if DEV:\n",
    "        return {\n",
    "        \"learning_rate\": tune.grid_search([2e-5, 3e-5, 5e-5]),\n",
    "        \"num_train_epochs\": tune.grid_search([2, 3, 4]),\n",
    "        \"per_device_train_batch_size\": tune.grid_search([4,8])\n",
    "    }\n",
    "    else:\n",
    "        return {\n",
    "            \"learning_rate\": tune.grid_search([2e-5, 3e-5, 5e-5]),\n",
    "            \"num_train_epochs\": tune.grid_search([2, 3, 4]),\n",
    "            \"per_device_train_batch_size\": tune.grid_search([16,32])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56347551",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run = trainer.hyperparameter_search(\n",
    "    backend = 'ray',\n",
    "    hp_space = custom_hp_space,\n",
    "    direction = 'minimize',\n",
    "    n_trials = 1,\n",
    "    progress_reporter = tune.JupyterNotebookReporter(overwrite=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a03d5b",
   "metadata": {},
   "source": [
    "2e-05\t4\t16\t4\t5804.12\t0.00772648\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f95d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fee0779",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n, v in best_run.hyperparameters.items():\n",
    "        setattr(trainer.args, n, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d35de63",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace33138",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./models/BERT_hateCheck+founta_weighted/final')\n",
    "tokenizer.save_pretrained('./models/BERT_hateCheck+founta_weighted/final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4156f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('./models/BERT_hateCheck+founta_weighted/final') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab1e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEV:\n",
    "    trainer = Trainer(\n",
    "        model=model,         \n",
    "        args=TrainingArguments(\n",
    "            output_dir=('./models/BERT_hateCheck_weighted/devTest'),\n",
    "            per_device_eval_batch_size = 64)\n",
    "    )\n",
    "else:\n",
    "    trainer = Trainer(\n",
    "        model=model,         \n",
    "        args=TrainingArguments(\n",
    "            output_dir=('./models/BERT_hateCheck_weighted/test'),\n",
    "            per_device_eval_batch_size = 64)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8706ad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results, train_preds = get_results(trainer, train_dataset_with_founta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705042bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_results, val_preds = get_results(trainer, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0447133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results, test_preds = get_results(trainer, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097c319b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"preds\"], df_train[\"split\"] = train_preds[:len(df_train)], \"train\"\n",
    "df_val[\"preds\"], df_val[\"split\"] = val_preds, \"val\"\n",
    "df_test[\"preds\"], df_test[\"split\"] = test_preds, \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe752c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df = pd.concat([df_train, df_val, df_test], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df[\"preds\"].replace({1: 'hateful', 0: 'non-hateful'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b56b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811c6209",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_df.to_pickle('./results/hatecheck/results_BERT_hateCheck+founta_weighted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8d5a11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checking-hateCheck",
   "language": "python",
   "name": "checking-hatecheck"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
