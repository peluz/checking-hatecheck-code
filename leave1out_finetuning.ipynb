{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ae972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from ray import tune\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from utils import initialize_seeds\n",
    "from data_utils import HateDataset, get_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05935622",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273e0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./hatecheck-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3f984b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_df = pd.read_csv(data_path/\"test_suite_cases.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe310428",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_df.label_gold.replace({'hateful': 1, 'non-hateful': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a997fa7",
   "metadata": {},
   "source": [
    "## Leave one functionality out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20922ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = pd.unique(hatecheck_df.functionality); funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173d6318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name())\n",
    "    print(torch.cuda.device_count(), 'GPUs')\n",
    "else:\n",
    "    print(\"Oops! No GPU found.\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbe71b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained(Path(\"./hatecheck-experiments/Models/BERT_davidson2017_weighted/Final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79dd564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data_one_out(df, held_out_col, funcs, tokenizer, task_train_df=None):\n",
    "    df_seen = df[~(df[held_out_col].isin(funcs))].copy()\n",
    "    df_unseen = df[(df[held_out_col].isin(funcs))].copy()\n",
    "    df_train, df_valtest = train_test_split(df_seen, test_size=0.5, stratify=df_seen.label_gold, random_state=42)\n",
    "    df_valtest = pd.concat([df_valtest, df_unseen])\n",
    "    df_val, df_test = train_test_split(df_valtest, test_size=0.5, stratify=df_valtest.label_gold, random_state=42)\n",
    "    \n",
    "    train_texts = df_train.test_case.astype(\"string\").tolist()\n",
    "    val_texts = df_val.test_case.astype(\"string\").tolist()\n",
    "    test_texts = df_test.test_case.astype(\"string\").tolist()\n",
    "\n",
    "    train_labels = df_train.label_gold.tolist()\n",
    "    val_labels = df_val.label_gold.tolist()\n",
    "    test_labels = df_test.label_gold.tolist()\n",
    "    \n",
    "    if task_train_df is not None:\n",
    "        train_texts += task_train_df.text.astype(\"string\").tolist()\n",
    "        train_labels += task_train_df.label.tolist()\n",
    "        \n",
    "    \n",
    "    class_weights = compute_class_weight('balanced', classes = np.unique(train_labels), y = train_labels)\n",
    "    \n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "    val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "    test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "        \n",
    "    train_dataset = HateDataset(train_encodings, train_labels)\n",
    "    val_dataset = HateDataset(val_encodings, val_labels)\n",
    "    test_dataset = HateDataset(test_encodings, test_labels)\n",
    "    return train_dataset, val_dataset, test_dataset, class_weights, df_train, df_val, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4590d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_config, train_dataset, val_dataset, name):\n",
    "    # Use best hperparameters found during the fixed held out fine tuning experiments\n",
    "    if train_config == \"davidson2017\":\n",
    "        training_args = TrainingArguments(\n",
    "        save_steps = 2500,\n",
    "        output_dir=\"./hatecheck-experiments/Models/leave1out/BERT_davidson2017_weighted_leave1out/checkpoints\", # output directory\n",
    "        save_strategy=\"no\",\n",
    "        num_train_epochs=4,              # total number of training epochs\n",
    "        per_device_train_batch_size=32,  # batch size per device during training\n",
    "        per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "        evaluation_strategy = 'epoch',\n",
    "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,               # strength of weight decay\n",
    "        learning_rate = 2e-5,\n",
    "        seed = 123,\n",
    "        disable_tqdm=True\n",
    "        )\n",
    "        model = BertForSequenceClassification.from_pretrained(f\"./hatecheck-experiments/Models/BERT_davidson2017_weighted/Final\")\n",
    "        model_path = f\"./hatecheck-experiments/Models/leave1out/BERT_{train_config}_hatecheck_weighted_leaveOut_{name}/Final\"\n",
    "        \n",
    "    elif train_config == \"founta2018\":\n",
    "        training_args = TrainingArguments(\n",
    "        save_steps = 2500,\n",
    "        output_dir=\"./hatecheck-experiments/Models/leave1out/BERT_founta2018_weighted_leave1out/checkpoints\", # output directory\n",
    "        save_strategy=\"no\",\n",
    "        num_train_epochs=3,              # total number of training epochs\n",
    "        per_device_train_batch_size=32,  # batch size per device during training\n",
    "        per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "        evaluation_strategy = 'epoch',\n",
    "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,               # strength of weight decay\n",
    "        learning_rate = 3e-5,\n",
    "        seed = 123,\n",
    "        disable_tqdm=True\n",
    "        )\n",
    "        model = BertForSequenceClassification.from_pretrained(f\"./hatecheck-experiments/Models/BERT_founta2018_weighted/Final\")\n",
    "        model_path = f\"./hatecheck-experiments/Models/leave1out/BERT_{train_config}_hatecheck_weighted_leaveOut_{name}/Final\"\n",
    "        \n",
    "    elif train_config == \"hateCheck+davidson\":\n",
    "        training_args = TrainingArguments(\n",
    "        save_steps = 2500,\n",
    "        output_dir=f\"./models/leave1out/BERT_{train_config}_weighted_leave1out/checkpoints\", # output directory\n",
    "        save_strategy=\"no\",\n",
    "        num_train_epochs=4,              # total number of training epochs\n",
    "        per_device_train_batch_size=16,  # batch size per device during training\n",
    "        per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "        evaluation_strategy = 'epoch',\n",
    "        warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "        weight_decay=0.01,               # strength of weight decay\n",
    "        learning_rate = 5e-5,\n",
    "        seed = 123,\n",
    "        disable_tqdm=True\n",
    "        )\n",
    "        model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        model_path = f\"./models/leave1out/BERT_{train_config}_weighted_leaveOut_{name}/final\"\n",
    "    \n",
    "    class WeightedTrainer(Trainer):\n",
    "        def compute_loss(self, model, inputs, return_outputs=False):\n",
    "            labels = inputs.pop(\"labels\")\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs[0]\n",
    "            weighted_loss = torch.nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights)).to(device)\n",
    "            return (weighted_loss(logits,labels), outputs) if return_outputs else weighted_loss(logits, labels)\n",
    "    \n",
    "    trainer = WeightedTrainer(\n",
    "        model=model,\n",
    "        args=training_args,                  \n",
    "        train_dataset=train_dataset,         \n",
    "        eval_dataset=val_dataset,            \n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(train_config, train_dataset, val_dataset, test_dataset, name):\n",
    "    if train_config == \"davidson2017\":\n",
    "        model = BertForSequenceClassification.from_pretrained(f\"./hatecheck-experiments/Models/leave1out/BERT_{train_config}_hatecheck_weighted_leaveOut_{name}/Final\")\n",
    "        model_path = f\"./hatecheck-experiments/Models/leave1out/BERT_{train_config}_hatecheck_weighted_leave1out/Test\"\n",
    "        \n",
    "    elif train_config == \"founta2018\":\n",
    "        model = BertForSequenceClassification.from_pretrained(f\"./hatecheck-experiments/Models/leave1out/BERT_{train_config}_hatecheck_weighted_leaveOut_{name}/Final\")\n",
    "        model_path = f\"./hatecheck-experiments/Models/leave1out/BERT_{train_config}_hatecheck_weighted_leave1out/Test\"\n",
    "        \n",
    "    elif train_config == \"hateCheck+davidson\":\n",
    "        model = BertForSequenceClassification.from_pretrained(f\"./models/leave1out/BERT_{train_config}_weighted_leaveOut_{name}/final\")\n",
    "        model_path = f\"./models/leave1out/BERT_{train_config}_weighted_leave1out/Test\"\n",
    "    trainer = Trainer(\n",
    "        model=model,         \n",
    "        args=TrainingArguments(\n",
    "            output_dir=(model_path),\n",
    "            per_device_eval_batch_size = 64)\n",
    "    )\n",
    "    print(\"Train set results:\")\n",
    "    train_results, train_preds = get_results(trainer, train_dataset)\n",
    "    print(\"Validation set results:\")\n",
    "    val_results, val_preds = get_results(trainer, val_dataset)\n",
    "    print(\"Test set results:\")\n",
    "    test_results, test_preds = get_results(trainer, test_dataset)\n",
    "    return train_preds, val_preds, test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126a8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_config in [\"davidson2017\", \"founta2018\"]:\n",
    "    for func in funcs:\n",
    "        print(f\"Preprocessing data leaving out {func}\")\n",
    "        train_dataset, val_dataset, test_dataset, class_weights, df_train, df_val, df_test = preprocess_data_one_out(hatecheck_df, \"functionality\", [func], tokenizer)\n",
    "        print(f\"Finetuning model pretrained on {train_config}\")\n",
    "        train_model(train_config, train_dataset, val_dataset, func)\n",
    "        train_preds, val_preds, test_preds = evaluate_model(train_config, train_dataset, val_dataset, test_dataset, func)\n",
    "        df_train[\"preds\"], df_train[\"split\"] = train_preds, \"train\"\n",
    "        df_val[\"preds\"], df_val[\"split\"] = val_preds, \"val\"\n",
    "        df_test[\"preds\"], df_test[\"split\"] = test_preds, \"test\"\n",
    "        preds_df = pd.concat([df_train, df_val, df_test], axis= 0)\n",
    "        preds_df[[\"case_id\", \"preds\", \"split\"]].to_pickle(f'./results/hatecheck/leave1out/results_BERT_{train_config}_weighted_leaveOut_{func}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f6f2f2",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7701fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pd.read_pickle('./hatecheck-experiments/Data/Clean Training Data/training_data_binary.pkl')\n",
    "\n",
    "df_raw = {}\n",
    "\n",
    "# write to dict\n",
    "for dataset in training_data:\n",
    "    df_raw[dataset] = training_data[dataset].copy()\n",
    "    \n",
    "df_train_target = {}\n",
    "\n",
    "for dataset in df_raw:\n",
    "    df_train_target[dataset], _ = train_test_split(df_raw[dataset], test_size=0.2, stratify=df_raw[dataset].label, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bdfc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_config in [\"hateCheck+davidson\"]:\n",
    "    for func in funcs:\n",
    "        print(f\"Preprocessing data leaving out {func}\")\n",
    "        train_dataset, val_dataset, test_dataset, class_weights, df_train, df_val, df_test = preprocess_data_one_out(hatecheck_df, \"functionality\", [func], tokenizer, df_train_target[\"davidson2017\"])\n",
    "        print(f\"Finetuning model with configuration {train_config}\")\n",
    "        train_model(train_config, train_dataset, val_dataset, func)\n",
    "        train_preds, val_preds, test_preds = evaluate_model(train_config, train_dataset, val_dataset, test_dataset, func)\n",
    "        df_train[\"preds\"], df_train[\"split\"] = train_preds[:len(df_train)], \"train\"\n",
    "        df_val[\"preds\"], df_val[\"split\"] = val_preds, \"val\"\n",
    "        df_test[\"preds\"], df_test[\"split\"] = test_preds, \"test\"\n",
    "        preds_df = pd.concat([df_train, df_val, df_test], axis= 0)\n",
    "        preds_df[[\"case_id\", \"preds\", \"split\"]].to_pickle(f'./results/hatecheck/leave1out/results_BERT_{train_config}_weighted_leaveOut_{func}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e248837a",
   "metadata": {},
   "source": [
    "## Leave one identity out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dba1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "idents = pd.unique(hatecheck_df[\"target_ident\"].dropna()); idents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259893ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pretrained_data in [\"davidson2017\", \"founta2018\"]:\n",
    "    for func in idents:\n",
    "        print(f\"Preprocessing data leaving out {func}\")\n",
    "        train_dataset, val_dataset, test_dataset, class_weights, df_train, df_val, df_test = preprocess_data_one_out(hatecheck_df, \"target_ident\", [func], tokenizer)\n",
    "        print(f\"Finetuning model pretrained on {pretrained_data}\")\n",
    "        train_model(pretrained_data, train_dataset, val_dataset, func)\n",
    "        train_preds, val_preds, test_preds = evaluate_model(pretrained_data, train_dataset, val_dataset, test_dataset, func)\n",
    "        df_train[\"preds\"], df_train[\"split\"] = train_preds, \"train\"\n",
    "        df_val[\"preds\"], df_val[\"split\"] = val_preds, \"val\"\n",
    "        df_test[\"preds\"], df_test[\"split\"] = test_preds, \"test\"\n",
    "        preds_df = pd.concat([df_train, df_val, df_test], axis= 0)\n",
    "        preds_df[[\"case_id\", \"preds\", \"split\"]].to_pickle(f'./results/hatecheck/leave1out/results_BERT_{pretrained_data}_weighted_leaveOut_{func}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853fd65",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d52816",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_config in [\"hateCheck+davidson\"]:\n",
    "    for func in idents:\n",
    "        print(f\"Preprocessing data leaving out {func}\")\n",
    "        train_dataset, val_dataset, test_dataset, class_weights, df_train, df_val, df_test = preprocess_data_one_out(hatecheck_df, \"functionality\", [func], tokenizer, df_train_target[\"davidson2017\"])\n",
    "        print(f\"Finetuning model with configuration {train_config}\")\n",
    "        train_model(train_config, train_dataset, val_dataset, func)\n",
    "        train_preds, val_preds, test_preds = evaluate_model(train_config, train_dataset, val_dataset, test_dataset, func)\n",
    "        df_train[\"preds\"], df_train[\"split\"] = train_preds[:len(df_train)], \"train\"\n",
    "        df_val[\"preds\"], df_val[\"split\"] = val_preds, \"val\"\n",
    "        df_test[\"preds\"], df_test[\"split\"] = test_preds, \"test\"\n",
    "        preds_df = pd.concat([df_train, df_val, df_test], axis= 0)\n",
    "        preds_df[[\"case_id\", \"preds\", \"split\"]].to_pickle(f'./results/hatecheck/leave1out/results_BERT_{train_config}_weighted_leaveOut_{func}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b68cea",
   "metadata": {},
   "source": [
    "## Leave one cluster out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1395026",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "for func in funcs:\n",
    "    clusters.setdefault(func.split(\"_\")[0], []).append(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fcb3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3ad71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pretrained_data in [\"davidson2017\", \"founta2018\"]:\n",
    "    for k, cluster in clusters.items():\n",
    "        print(f\"Preprocessing data leaving out {k}\")\n",
    "        train_dataset, val_dataset, test_dataset, class_weights, df_train, df_val, df_test = preprocess_data_one_out(hatecheck_df, \"functionality\", cluster, tokenizer)\n",
    "        print(f\"Finetuning model pretrained on {pretrained_data}\")\n",
    "        train_model(pretrained_data, train_dataset, val_dataset, k)\n",
    "        train_preds, val_preds, test_preds = evaluate_model(pretrained_data, train_dataset, val_dataset, test_dataset, k)\n",
    "        df_train[\"preds\"], df_train[\"split\"] = train_preds, \"train\"\n",
    "        df_val[\"preds\"], df_val[\"split\"] = val_preds, \"val\"\n",
    "        df_test[\"preds\"], df_test[\"split\"] = test_preds, \"test\"\n",
    "        preds_df = pd.concat([df_train, df_val, df_test], axis= 0)\n",
    "        preds_df[[\"case_id\", \"preds\", \"split\"]].to_pickle(f'./results/hatecheck/leave1out/results_BERT_{pretrained_data}_weighted_leaveOut_{k}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512dee14",
   "metadata": {},
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493cf3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_config in [\"hateCheck+davidson\"]:\n",
    "    for k, cluster in clusters.items():\n",
    "        print(f\"Preprocessing data leaving out {k}\")\n",
    "        train_dataset, val_dataset, test_dataset, class_weights, df_train, df_val, df_test = preprocess_data_one_out(hatecheck_df, \"functionality\", cluster, tokenizer, df_train_target[\"davidson2017\"])\n",
    "        print(f\"Finetuning model with configuration {train_config}\")\n",
    "        train_model(train_config, train_dataset, val_dataset, k)\n",
    "        train_preds, val_preds, test_preds = evaluate_model(train_config, train_dataset, val_dataset, test_dataset, k)\n",
    "        df_train[\"preds\"], df_train[\"split\"] = train_preds[:len(df_train)], \"train\"\n",
    "        df_val[\"preds\"], df_val[\"split\"] = val_preds, \"val\"\n",
    "        df_test[\"preds\"], df_test[\"split\"] = test_preds, \"test\"\n",
    "        preds_df = pd.concat([df_train, df_val, df_test], axis= 0)\n",
    "        preds_df[[\"case_id\", \"preds\", \"split\"]].to_pickle(f'./results/hatecheck/leave1out/results_BERT_{train_config}_weighted_leaveOut_{k}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a42c926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checking-hateCheck",
   "language": "python",
   "name": "checking-hatecheck"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
