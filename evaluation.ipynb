{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9833ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report, accuracy_score\n",
    "from pathlib import Path\n",
    "\n",
    "from utils import initialize_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bda55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b312b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ff667",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"./hatecheck-data\")\n",
    "results_path = Path(\"./results/hatecheck/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fb5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_df = pd.read_csv(data_path/\"test_suite_cases.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b53785",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls {results_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ff3018",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results[\"random\"] = pd.read_pickle(results_path/\"results_BERT_weighted.pkl\")[[\"case_id\", \"preds\", \"split\"]]\n",
    "results[\"unseen\"] = pd.read_pickle(results_path/\"results_BERT_weighted_unseen.pkl\")[[\"case_id\", \"preds\", \"split\"]]\n",
    "results[\"davidson2017_random\"] = pd.read_pickle(results_path/\"results_BERT_davidson2017_weighted.pkl\")[[\"case_id\", \"preds\"]]\n",
    "results[\"davidson2017_unseen\"] = pd.read_pickle(results_path/\"results_BERT_davidson2017_weighted_unseen.pkl\")[[\"case_id\", \"preds\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0abe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"founta2018_random\"] = pd.read_pickle(results_path/\"results_BERT_founta2018_weighted.pkl\")[[\"case_id\", \"preds\"]]\n",
    "results[\"founta2018_unseen\"] = pd.read_pickle(results_path/\"results_BERT_founta2018_weighted_unseen.pkl\")[[\"case_id\", \"preds\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b2b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fine_tune_results =pd.read_pickle('./results/hatecheck/results_BERT_davidson_and_founta_weighted.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ff9f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_fine_tune_results.rename(columns = {\"pred_BERT_davidson2017_weighted\": \"davidson2017_nofinetune_preds\",\n",
    "                             \"pred_BERT_founta2018_weighted\": \"founta2018_nofinetune_preds\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"founta2018_nofinetune\"] = no_fine_tune_results[[\"case_id\", \"founta2018_nofinetune_preds\"]].copy()\n",
    "results[\"davidson2017_nofinetune\"] = no_fine_tune_results[[\"case_id\", \"davidson2017_nofinetune_preds\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ebd4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"hatecheck+davidson\"] = pd.read_pickle(results_path/\"results_BERT_hateCheck+davidson_weighted.pkl\")[[\"case_id\", \"preds\", \"split\"]]\n",
    "results[\"hatecheck+founta\"] = pd.read_pickle(results_path/\"results_BERT_hateCheck+founta_weighted.pkl\")[[\"case_id\", \"preds\", \"split\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e95dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with hatecheck df\n",
    "for model in results:\n",
    "    results[model].rename(columns={\"preds\": f\"{model}_preds\", \"split\": f\"{model}_splits\"}, inplace=True)\n",
    "    hatecheck_df = hatecheck_df.merge(results[model], how='left', on='case_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb4115",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe63ad1",
   "metadata": {},
   "source": [
    "### Insert majority baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ce9e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_df[\"majority_preds\"] = \"hateful\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8cab9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9122b",
   "metadata": {},
   "source": [
    "## Evalation by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabe5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import binomtest\n",
    "\n",
    "\n",
    "def get_significance(preds_1, preds_2, labels):\n",
    "    corrects1 = (np.array(preds_1) == np.array(labels)).astype(int)\n",
    "    corrects2 = (np.array(preds_2) == np.array(labels)).astype(int)\n",
    "    diffs = corrects2 - corrects1\n",
    "    successes = (diffs == 1).sum()\n",
    "    trials = np.abs(diffs).sum()\n",
    "    return binomtest(successes, trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1194b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples = hatecheck_df[hatecheck_df[\"random_splits\"] == \"test\"]\n",
    "for model in [\"davidson2017_nofinetune\", \"davidson2017_random\", \"founta2018_nofinetune\",\n",
    "              \"founta2018_random\", \"random\", \"hatecheck+davidson\", \"hatecheck+founta\"]:\n",
    "    preds = test_samples[f\"{model}_preds\"].tolist()\n",
    "    labels = test_samples[\"label_gold\"].tolist()\n",
    "    print(f\"Results for {model}:\")\n",
    "    print(classification_report(labels, preds,digits=4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d09bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in [\"davidson2017\", \"founta2018\"]:\n",
    "    print(get_significance(test_samples[f\"{model}_nofinetune_preds\"].tolist(),\n",
    "                           test_samples[f\"{model}_random_preds\"].tolist(),\n",
    "                           test_samples[\"label_gold\"].tolist()))\n",
    "    print(get_significance(test_samples[f\"{model}_nofinetune_preds\"].tolist(),\n",
    "                           test_samples[f\"hatecheck+{model[:-4]}_preds\"].tolist(),\n",
    "                           test_samples[\"label_gold\"].tolist()))\n",
    "    print(get_significance(test_samples[f\"{model}_random_preds\"].tolist(),\n",
    "                           test_samples[f\"random_preds\"].tolist(),\n",
    "                           test_samples[\"label_gold\"].tolist()))\n",
    "    print(get_significance(test_samples[f\"{model}_random_preds\"].tolist(),\n",
    "                           test_samples[f\"hatecheck+{model[:-4]}_preds\"].tolist(),\n",
    "                           test_samples[\"label_gold\"].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e14ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_significance(test_samples[\"davidson2017_random_preds\"].tolist(),\n",
    "                           test_samples[\"founta2018_random_preds\"].tolist(),\n",
    "                           test_samples[\"label_gold\"].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c51cb5",
   "metadata": {},
   "source": [
    "## Evaluation by functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cc0a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, group in hatecheck_df.groupby(\"unseen_splits\"):\n",
    "    print(pd.unique(group.functionality))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b850d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/held_out_dic.pkl\", \"rb\") as file:\n",
    "    held_out_dic = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d68276",
   "metadata": {},
   "outputs": [],
   "source": [
    "held_out_funcs = held_out_dic[\"hateful_funcs\"] + held_out_dic[\"nonhateful_funcs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db086826",
   "metadata": {},
   "outputs": [],
   "source": [
    "held_out_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab59c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "held_out_idents = held_out_dic[\"idents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc743a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_df(results, func_col, pred_col, split_col):\n",
    "    dic = {}\n",
    "    for group, df in results.groupby(split_col):\n",
    "        dic[group] = []\n",
    "        for x in pd.unique(results[func_col]):\n",
    "            n_cases = df[df[func_col]==x].shape[0]\n",
    "            if n_cases == 0:\n",
    "                dic[group].append(None)\n",
    "            else:\n",
    "                n_correct = df[(df[func_col]==x)&(df['label_gold']==df[pred_col])].shape[0]\n",
    "                dic[group].append(n_correct/n_cases)\n",
    "        dic[group] = pd.Series(dic[group])\n",
    "        dic[group].name = group\n",
    "        \n",
    "    dic[\"overall\"] = []\n",
    "    for x in pd.unique(results[func_col]):\n",
    "        n_cases = results[results[func_col]==x].shape[0]\n",
    "        n_correct = results[(results[func_col]==x)&(results['label_gold']==results[pred_col])].shape[0]\n",
    "        dic[\"overall\"].append(n_correct/n_cases)\n",
    "    dic[\"overall\"] = pd.Series(dic[\"overall\"])\n",
    "    dic[\"overall\"].name = \"overall\"\n",
    "        \n",
    "    # create df from dict\n",
    "    df = pd.Series(pd.unique(results[func_col]))\n",
    "    df.name = func_col\n",
    "\n",
    "    for acc_data in dic:\n",
    "        df = pd.concat([df, pd.Series(dic[acc_data])], axis =1)\n",
    "\n",
    "    cols = [func_col, \"overall\", \"train\", \"val\", \"test\"]\n",
    "    return df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1e4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_seen_unseen(accuracy_df, col, held_out, split):\n",
    "    return (accuracy_df[~accuracy_df[col].isin(held_out)][split],\n",
    "            accuracy_df[accuracy_df[col].isin(held_out)][split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd01740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results(results, target_df, func, held_out):\n",
    "    results_dic = {}\n",
    "    for model in results:\n",
    "        if model[-6:] == \"random\":\n",
    "            splits = [\"random\"]\n",
    "        elif model[-6:] == \"unseen\":\n",
    "            splits = [\"unseen\"]\n",
    "        else:\n",
    "            splits = [\"random\", \"unseen\"]\n",
    "        for split in splits:\n",
    "            print(f\"Results for {model} on the {split} split:\")\n",
    "            df = results_to_df(target_df, func, f\"{model}_preds\", f\"{split}_splits\")\n",
    "            results_dic[(model,split)] = df\n",
    "            print(df)\n",
    "            print(df.describe())\n",
    "            seen, unseen = comp_seen_unseen(df, func, held_out, \"test\")\n",
    "            print(seen)\n",
    "            print(unseen)\n",
    "            print(seen.describe())\n",
    "            print(unseen.describe())\n",
    "            print()\n",
    "    return results_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd534f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_results = compare_results(results, hatecheck_df, \"functionality\", held_out_funcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa5936",
   "metadata": {},
   "source": [
    "## Evaluation by protected group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238e2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df with only template cases --> number of cases for each identity should be balanced\\n\",\n",
    "templ_cases_df = hatecheck_df[hatecheck_df.case_templ.str.contains('IDENTITY')].copy()\n",
    "templ_cases_df.groupby(templ_cases_df.target_ident).case_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1265d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"majority\"] = hatecheck_df[[\"case_id\", \"majority_preds\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82eff85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results(results, templ_cases_df, \"target_ident\", held_out_idents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041d1a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_results(results, hatecheck_df.dropna(subset=[\"target_ident\"]), \"target_ident\", held_out_idents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27056727",
   "metadata": {},
   "source": [
    "## Evaluate 1out results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hatecheck_df = pd.read_csv(data_path/\"test_suite_cases.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2361b7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = Path(\"./results/hatecheck/leave1out/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56251480",
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls ./results/hatecheck/leave1out/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2b146",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_1out = {}\n",
    "for col in [\"functionality\", \"target_ident\"]:\n",
    "    results_1out[col] = {}\n",
    "    for model in [\"davidson2017\", \"founta2018\", \"hateCheck+davidson\", \"hateCheck+founta\"]:\n",
    "        results_1out[col][model] = {}\n",
    "        if col==\"functionality\":\n",
    "            phenom_set =  pd.unique(hatecheck_df[col])\n",
    "        else:\n",
    "            phenom_set = pd.unique(hatecheck_df.dropna(subset=[\"target_ident\"])[col])\n",
    "        for func in phenom_set:\n",
    "            results_1out[col][model][func] = pd.read_pickle(results_path/f\"results_BERT_{model}_weighted_leaveOut_{func}.pkl\")[[\"case_id\", \"preds\", \"split\"]]\n",
    "            results_1out[col][model][func].replace({1: 'hateful', 0: 'non-hateful'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2531d79a",
   "metadata": {},
   "source": [
    "### Overall accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf679dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies(results, df, model, col, splits=[\"test\"], return_preds=False):\n",
    "    seen_acc = []\n",
    "    unseen_preds = []\n",
    "    unseen_labels = []\n",
    "    for k, v in results[col][model].items():\n",
    "        v.rename(columns={\"preds\": f\"{k}_preds\", \"split\": f\"{k}_splits\"}, inplace=True)\n",
    "        df_with_preds = df.merge(v , how='left', on='case_id')\n",
    "        unseen_test_samples = df_with_preds[(df_with_preds[f\"{k}_splits\"].isin(splits)) & (df_with_preds[col] == k)][[\"label_gold\", f\"{k}_preds\"]]\n",
    "        seen_test_samples = df_with_preds[(df_with_preds[f\"{k}_splits\"].isin(splits)) & (df_with_preds[col] != k)][[\"label_gold\", f\"{k}_preds\"]]\n",
    "        seen_acc.append(accuracy_score(seen_test_samples[\"label_gold\"], seen_test_samples[f\"{k}_preds\"]))\n",
    "        unseen_preds.extend(unseen_test_samples[f\"{k}_preds\"])\n",
    "        unseen_labels.extend(unseen_test_samples[\"label_gold\"])\n",
    "    avg_seen_acc = np.array(seen_acc).mean()\n",
    "    unseen_acc = accuracy_score(unseen_labels, unseen_preds)\n",
    "    if return_preds:\n",
    "        return unseen_preds, unseen_labels\n",
    "    return avg_seen_acc, unseen_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5aad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_accuracies(results_1out, hatecheck_df, \"davidson2017\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7bb28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracies(results_1out, hatecheck_df, \"founta2018\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b3facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracies(results_1out, hatecheck_df, \"hateCheck+davidson\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df57f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracies(results_1out, hatecheck_df, \"hateCheck+founta\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0962ee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "get_accuracies(results_1out, hatecheck_df, \"davidson2017\", \"target_ident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e06cd7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_accuracies(results_1out, hatecheck_df, \"founta2018\", \"target_ident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925a304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracies(results_1out, hatecheck_df, \"hateCheck+davidson\", \"target_ident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de24d967",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracies(results_1out, hatecheck_df, \"hateCheck+founta\", \"target_ident\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a441aeb",
   "metadata": {},
   "source": [
    "### Results by func/ident"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214df4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_results(results, df, model, col):\n",
    "    seen_funcs = pd.DataFrame()\n",
    "    held_out_funcs = pd.DataFrame()\n",
    "    seen_accs = []\n",
    "    test_samples = {}\n",
    "    for k, v in results[col][model].items():\n",
    "        v.rename(columns={\"preds\": f\"{k}_preds\", \"split\": f\"{k}_splits\"}, inplace=True)\n",
    "        df_with_preds = df.merge(v , how='left', on='case_id')\n",
    "        func_df = results_to_df(df_with_preds, col, f\"{k}_preds\", f\"{k}_splits\")\n",
    "        seen_funcs = pd.concat([seen_funcs, func_df[func_df[col] != k]], axis =0) \n",
    "        held_out_funcs = pd.concat([held_out_funcs, func_df[func_df[col] == k]], axis =0)\n",
    "        test_samples[k] = df_with_preds[(df_with_preds[f\"{k}_splits\"]==\"test\") & (df_with_preds[col] == k)][[\"case_id\", \"label_gold\"]]\n",
    "        \n",
    "    return seen_funcs, held_out_funcs, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaed510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_agg(agg, col, df):\n",
    "    return agg.groupby(col).agg(['mean','std']).reindex(pd.unique(df[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb049e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_results(test_samples, model, results):\n",
    "    results_dic = {}\n",
    "    all_df = pd.DataFrame()\n",
    "    for k, v in test_samples.items():\n",
    "        df = results[model].merge(v)\n",
    "        all_df = pd.concat([all_df, df], axis=0)\n",
    "        results_dic[k] = (df[f\"{model}_preds\"] == df[\"label_gold\"]).mean()\n",
    "    return pd.DataFrame.from_dict(results_dic, orient=\"index\"), accuracy_score(all_df.label_gold, all_df[f\"{model}_preds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1012eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds_and_labels(test_samples, model, results):\n",
    "    preds = []\n",
    "    labels = []\n",
    "    all_df = pd.DataFrame()\n",
    "    for k, v in test_samples.items():\n",
    "        df = results[model].merge(v)\n",
    "        all_df = pd.concat([all_df, df], axis=0)\n",
    "        preds.extend(df[f\"{model}_preds\"])\n",
    "        labels.extend(df[\"label_gold\"])\n",
    "    return preds, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77b605e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_funcs_davidson, held_out_funcs_davidson, test_samples = aggregate_results(results_1out, hatecheck_df, \"davidson2017\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0b4cbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_agg(seen_funcs_davidson, \"functionality\", hatecheck_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc2eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "held_out_funcs_davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c44888",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"davidson2017_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"davidson2017\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65180a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_funcs_hateCheckPlusdavidson, held_out_funcs_hateCheckPlusdavidson, test_samples = aggregate_results(results_1out, hatecheck_df, \"hateCheck+davidson\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a00559f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_agg(seen_funcs_hateCheckPlusdavidson, \"functionality\", hatecheck_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8841ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "held_out_funcs_hateCheckPlusdavidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae5283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_test_results(test_samples, \"davidson2017_nofinetune\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1e323",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"davidson2017_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"hateCheck+davidson\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5232eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_funcs_founta, held_out_funcs_founta, test_samples = aggregate_results(results_1out, hatecheck_df, \"founta2018\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600757ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_agg(seen_funcs_founta, \"functionality\", hatecheck_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb77e23b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "held_out_funcs_founta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90232760",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_results(test_samples, \"founta2018_nofinetune\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff82a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"founta2018_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"founta2018\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0260c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_funcs_hateCheckPlusfounta, held_out_funcs_hateCheckPlusfounta, test_samples = aggregate_results(results_1out, hatecheck_df, \"hateCheck+founta\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eaaaff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_agg(seen_funcs_hateCheckPlusfounta, \"functionality\", hatecheck_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acc5d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "held_out_funcs_hateCheckPlusfounta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37139fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"founta2018_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"hateCheck+founta\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a424503",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_accuracies(results_1out, hatecheck_df, \"founta2018\", \"functionality\", return_preds=True)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"hateCheck+founta\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb535be",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_accuracies(results_1out, hatecheck_df, \"davidson2017\", \"functionality\", return_preds=True)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"hateCheck+davidson\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6150b514",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_idents_davidson, held_out_idents_davidson, test_samples = aggregate_results(results_1out, hatecheck_df.dropna(subset=[\"target_ident\"]), \"davidson2017\", \"target_ident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1962ada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_agg(seen_idents_davidson, \"target_ident\", hatecheck_df.dropna(subset=[\"target_ident\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983e1da7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "held_out_idents_davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c60312",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"davidson2017_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"davidson2017\", \"target_ident\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1876f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_idents_hateCheckPlusdavidson, held_out_idents_hateCheckPlusdavidson, test_samples = aggregate_results(results_1out, hatecheck_df.dropna(subset=[\"target_ident\"]), \"hateCheck+davidson\", \"target_ident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e32fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_agg(seen_idents_hateCheckPlusdavidson, \"target_ident\", hatecheck_df.dropna(subset=[\"target_ident\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ad9923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "held_out_idents_hateCheckPlusdavidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8469b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_results(test_samples, \"davidson2017_nofinetune\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e0380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"davidson2017_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"hateCheck+davidson\", \"target_ident\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd5cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_idents_founta, held_out_idents_founta, test_samples = aggregate_results(results_1out, hatecheck_df.dropna(subset=[\"target_ident\"]), \"founta2018\", \"target_ident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_agg(seen_idents_founta, \"target_ident\", hatecheck_df.dropna(subset=[\"target_ident\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53396f24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "held_out_idents_founta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a04825",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_results(test_samples, \"founta2018_nofinetune\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80a1169",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"founta2018_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"founta2018\", \"target_ident\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f8b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_idents_hateCheckPlusfounta, held_out_idents_hateCheckPlusfounta, test_samples = aggregate_results(results_1out, hatecheck_df.dropna(subset=[\"target_ident\"]), \"hateCheck+founta\", \"target_ident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8ad85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_agg(seen_idents_hateCheckPlusfounta, \"target_ident\", hatecheck_df.dropna(subset=[\"target_ident\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39228a74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "held_out_idents_hateCheckPlusfounta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c164ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"founta2018_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"hateCheck+founta\", \"target_ident\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101973d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_accuracies(results_1out, hatecheck_df, \"founta2018\", \"target_ident\", return_preds=True)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"hateCheck+founta\", \"target_ident\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f83e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_accuracies(results_1out, hatecheck_df, \"davidson2017\", \"target_ident\", return_preds=True)\n",
    "preds2, labels2 = get_accuracies(results_1out, hatecheck_df, \"hateCheck+davidson\", \"target_ident\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abda6bcb",
   "metadata": {},
   "source": [
    "## Cluster results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "for func in pd.unique(hatecheck_df.functionality):\n",
    "    clusters.setdefault(func.split(\"_\")[0], []).append(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059aa498",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca2ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_clusterOut = {}\n",
    "for model in [\"davidson2017\", \"founta2018\", \"hateCheck+davidson\", \"hateCheck+founta\"]:\n",
    "    results_clusterOut[model] = {}\n",
    "    for cluster in clusters:\n",
    "        results_clusterOut[model][cluster] = pd.read_pickle(results_path/f\"results_BERT_{model}_weighted_leaveOut_{cluster}.pkl\")[[\"case_id\", \"preds\", \"split\"]]\n",
    "        results_clusterOut[model][cluster].replace({1: 'hateful', 0: 'non-hateful'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95570f5a",
   "metadata": {},
   "source": [
    "### Overall accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4815e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracies_clusterOut(results, df, model, col, splits=[\"test\"], return_preds=False):\n",
    "    seen_acc = []\n",
    "    unseen_preds = []\n",
    "    unseen_labels = []\n",
    "    for k, v in results[model].items():\n",
    "        v.rename(columns={\"preds\": f\"{k}_preds\", \"split\": f\"{k}_splits\"}, inplace=True)\n",
    "        df_with_preds = df.merge(v , how='left', on='case_id')\n",
    "        unseen_test_samples = df_with_preds[(df_with_preds[f\"{k}_splits\"].isin(splits)) & (df_with_preds[col].isin(clusters[k]))][[\"label_gold\", f\"{k}_preds\"]]\n",
    "        seen_test_samples = df_with_preds[(df_with_preds[f\"{k}_splits\"].isin(splits)) & ~(df_with_preds[col].isin(clusters[k]))][[\"label_gold\", f\"{k}_preds\"]]\n",
    "        seen_acc.append(accuracy_score(seen_test_samples[\"label_gold\"], seen_test_samples[f\"{k}_preds\"]))\n",
    "        unseen_preds.extend(unseen_test_samples[f\"{k}_preds\"])\n",
    "        unseen_labels.extend(unseen_test_samples[\"label_gold\"])\n",
    "    avg_seen_acc = np.array(seen_acc).mean()\n",
    "    unseen_acc = accuracy_score(unseen_labels, unseen_preds)\n",
    "    if return_preds:\n",
    "        return unseen_preds, unseen_labels\n",
    "    return avg_seen_acc, unseen_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a8032",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"davidson2017\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9814dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"founta2018\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523bc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"hateCheck+davidson\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"hateCheck+founta\", \"functionality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805afd24",
   "metadata": {},
   "source": [
    "### Results by cluster and func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_cluster_results(results, df, model, col):\n",
    "    seen_funcs = pd.DataFrame()\n",
    "    held_out_funcs = pd.DataFrame()\n",
    "    test_samples_cluster = {}\n",
    "    test_samples = {}\n",
    "    for k, v in results[model].items():\n",
    "        v.rename(columns={\"preds\": f\"{k}_preds\", \"split\": f\"{k}_splits\"}, inplace=True)\n",
    "        df_with_preds = df.merge(v , how='left', on='case_id')\n",
    "        func_df = results_to_df(df_with_preds, col, f\"{k}_preds\", f\"{k}_splits\")\n",
    "        seen_funcs = pd.concat([seen_funcs, func_df[~(func_df[col].isin(clusters[k]))]], axis =0) \n",
    "        held_out_funcs = pd.concat([held_out_funcs, func_df[(func_df[col].isin(clusters[k]))]], axis =0) \n",
    "        test_samples_cluster[k] = df_with_preds[(df_with_preds[f\"{k}_splits\"]==\"test\") & (df_with_preds[col].isin(clusters[k]))][[\"case_id\", \"label_gold\"]]\n",
    "        for func in clusters[k]:\n",
    "            test_samples[func] = df_with_preds[(df_with_preds[f\"{k}_splits\"]==\"test\") & (df_with_preds[col] == func)][[\"case_id\", \"label_gold\"]]\n",
    "    return seen_funcs, held_out_funcs, test_samples_cluster, test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ab6127",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_clusters_davidson, held_out_clusters_davidson, test_samples_cluster, test_samples = aggregate_cluster_results(results_clusterOut, hatecheck_df, \"davidson2017\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c2f224",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_agg(seen_clusters_davidson, \"functionality\", hatecheck_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7c3748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "held_out_clusters_davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_results(test_samples, \"davidson2017_nofinetune\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95706a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_results(test_samples_cluster, \"davidson2017_nofinetune\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e4f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"davidson2017_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"davidson2017\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15436b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"davidson2017_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"hateCheck+davidson\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e97b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"davidson2017\", \"functionality\", return_preds=True)\n",
    "preds2, labels2 = get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"hateCheck+davidson\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c704e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dic = {}\n",
    "for k, v in test_samples_cluster.items():\n",
    "        df = results_clusterOut[\"davidson2017\"][k].merge(v)\n",
    "        results_dic[k] = (df[f\"{k}_preds\"] == df[\"label_gold\"]).mean()\n",
    "pd.DataFrame.from_dict(results_dic, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4082e14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "held_out_idents_davidson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb276da",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_idents_davidson, held_out_idents_davidson, test_samples_cluster, test_samples = aggregate_cluster_results(results_clusterOut, hatecheck_df.dropna(subset=[\"target_ident\"]), \"davidson2017\", \"target_ident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca01e24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_agg(seen_idents_davidson, \"target_ident\", hatecheck_df.dropna(subset=[\"target_ident\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_clusters_founta, held_out_clusters_founta, test_samples_cluster, test_samples = aggregate_cluster_results(results_clusterOut, hatecheck_df, \"founta2018\", \"functionality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc564d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "display_agg(seen_clusters_founta, \"functionality\", hatecheck_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3f9986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "held_out_clusters_founta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfdd360",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_results(test_samples, \"founta2018_nofinetune\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc731319",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_test_results(test_samples_cluster, \"founta2018_nofinetune\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b618e39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"founta2018_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"founta2018\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7555979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_preds_and_labels(test_samples, \"founta2018_nofinetune\", results)\n",
    "preds2, labels2 = get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"hateCheck+founta\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11702055",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds1, labels1 = get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"founta2018\", \"functionality\", return_preds=True)\n",
    "preds2, labels2 = get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"hateCheck+founta\", \"functionality\", return_preds=True)\n",
    "assert labels1==labels2\n",
    "print(get_significance(preds1, preds2, labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eead5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dic = {}\n",
    "for k, v in test_samples_cluster.items():\n",
    "        df = results_clusterOut[\"founta2018\"][k].merge(v)\n",
    "        results_dic[k] = (df[f\"{k}_preds\"] == df[\"label_gold\"]).mean()\n",
    "pd.DataFrame.from_dict(results_dic, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25e4f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "seen_idents_founta, held_out_idents_founta, test_samples_cluster, test_samples = aggregate_cluster_results(results_clusterOut, hatecheck_df.dropna(subset=[\"target_ident\"]), \"founta2018\", \"target_ident\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76996978",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_agg(seen_idents_founta, \"target_ident\", hatecheck_df.dropna(subset=[\"target_ident\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71de9794",
   "metadata": {},
   "source": [
    "## Leave1out vs leaveClusterOut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71978e",
   "metadata": {},
   "source": [
    "### Overall accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa4b11d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"davidson2017\", \"functionality\", splits=[\"val\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f155ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracies_clusterOut(results_clusterOut, hatecheck_df, \"founta2018\", \"functionality\", splits=[\"val\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760aab02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_accuracies(results_1out, hatecheck_df, \"davidson2017\", \"functionality\", splits=[\"val\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracies(results_1out, hatecheck_df, \"founta2018\", \"functionality\", splits=[\"val\", \"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b66021",
   "metadata": {},
   "source": [
    "### Results by cluster and func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9defb4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_cluster_v_1out(model):\n",
    "    leave1outResults={}\n",
    "    leave1clusterResults={}\n",
    "    for cluster, funcs in clusters.items():\n",
    "        preds_and_label_by_cluster = pd.DataFrame()\n",
    "        for func in funcs:\n",
    "            preds_and_labels = results_1out[\"functionality\"][model][func].merge(results_clusterOut[model][cluster]).merge(hatecheck_df[[\"case_id\", \"label_gold\", \"functionality\"]])\n",
    "            preds_and_label_by_func = preds_and_labels[preds_and_labels.functionality == func]\n",
    "            preds_and_label_by_cluster = pd.concat([preds_and_label_by_cluster, preds_and_label_by_func.rename(columns={f\"{func}_preds\": \"1out_preds\"})], axis=0)\n",
    "            leave1outResults[func] = (preds_and_label_by_func[f\"{func}_preds\"] == preds_and_label_by_func[\"label_gold\"]).mean()\n",
    "            leave1clusterResults[func] = (preds_and_label_by_func[f\"{cluster}_preds\"] == preds_and_label_by_func[\"label_gold\"]).mean()\n",
    "        leave1outResults[cluster] = (preds_and_label_by_cluster[f\"1out_preds\"] == preds_and_label_by_cluster[\"label_gold\"]).mean()\n",
    "        leave1clusterResults[cluster] = (preds_and_label_by_cluster[f\"{cluster}_preds\"] == preds_and_label_by_cluster[\"label_gold\"]).mean()\n",
    "    return pd.DataFrame.from_dict(leave1outResults, orient=\"index\"), pd.DataFrame.from_dict(leave1clusterResults, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e2e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave1out_davidson, leave1cluster_davidson = results_cluster_v_1out(\"davidson2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd74c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = pd.unique(hatecheck_df.functionality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd1170f",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave1out_davidson[leave1out_davidson.index.isin(funcs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c420c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave1out_davidson[leave1out_davidson.index.isin(clusters.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280640c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave1cluster_davidson[leave1cluster_davidson.index.isin(funcs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9037fffa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "leave1cluster_davidson[leave1cluster_davidson.index.isin(clusters.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad4a65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave1out_founta, leave1cluster_founta = results_cluster_v_1out(\"founta2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff656ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave1out_founta[leave1out_founta.index.isin(funcs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5240f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave1out_founta[leave1out_founta.index.isin(clusters.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4531f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave1cluster_founta[leave1cluster_founta.index.isin(funcs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49705851",
   "metadata": {},
   "outputs": [],
   "source": [
    "leave1cluster_founta[leave1cluster_founta.index.isin(clusters.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d8ba32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checking-hateCheck",
   "language": "python",
   "name": "checking-hatecheck"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
