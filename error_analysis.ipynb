{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b134d9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import pickle\n",
    "\n",
    "from data_utils import HateDataset, get_results\n",
    "from utils import initialize_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21868888",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d63f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./data/targetData.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a63c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d9169",
   "metadata": {},
   "source": [
    "## Get predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('hatecheck-experiments/Models/BERT_davidson2017_weighted/Final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec03bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"davidson2017\", \"founta2018\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for name in model_names:\n",
    "    model = BertForSequenceClassification.from_pretrained(f\"./hatecheck-experiments/Models/BERT_{name}_weighted/Final\")\n",
    "    trainer = Trainer(\n",
    "        model=model,         \n",
    "        args=TrainingArguments(\n",
    "            output_dir=(f\"./hatecheck-experiments/Models/BERT_{name}_weighted/test\"),\n",
    "            per_device_eval_batch_size = 64)\n",
    "    )\n",
    "    print(f\"Evaluating model pretrained on {name} on {name} validation set\")\n",
    "    results[name], _= get_results(trainer, data[1][name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b125b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in model_names:\n",
    "    model = BertForSequenceClassification.from_pretrained(f\"./hatecheck-experiments/Models/BERT_{name}_hatecheck_weighted/Final\")\n",
    "    trainer = Trainer(\n",
    "        model=model,         \n",
    "        args=TrainingArguments(\n",
    "            output_dir=(f\"./models/BERT_hateCheck_weighted/test\"),\n",
    "            per_device_eval_batch_size = 64)\n",
    "    )\n",
    "    print(f\"Evaluating model finetuned on random split hatecheck on {name} validation set\")\n",
    "    results[f\"BERT-R_{name}\"], _= get_results(trainer, data[1][name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb477e7",
   "metadata": {},
   "source": [
    "## Get samples with worse degradation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bfdbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./results/iid_preds.pkl\", \"wb\") as file:\n",
    "    pickle.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cf3569",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pickle.load(open(\"./results/iid_preds.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dd8ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "def get_non_hate_probs(result):\n",
    "    return softmax(result[0], axis=1)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5920133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deltas_df(results, data_name):\n",
    "    p_non_hate_before, p_non_hate_after = get_non_hate_probs(results[data_name]), get_non_hate_probs(results[f\"BERT-R_{data_name}\"])\n",
    "    deltas = pd.DataFrame((p_non_hate_after - p_non_hate_before).squeeze(), columns=[\"delta\"])\n",
    "    deltas[\"label\"] = results[data_name][1]\n",
    "    return deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c77768",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_davidson = get_deltas_df(results, \"davidson2017\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb87e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas_founta = get_deltas_df(results, \"founta2018\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dab398",
   "metadata": {},
   "source": [
    "## Largest degradations for hateful samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0343776",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(results, data, data_name, tokenizer, idxs):\n",
    "    samples = [tokenizer.decode(data[data_name][i][\"input_ids\"]) for i in idxs]\n",
    "    labels = [results[data_name][1][i] for i in idxs]\n",
    "    pred_before = [results[data_name][0][i] for i in idxs]\n",
    "    pred_after = [results[f\"BERT-R_{data_name}\"][0][i] for i in idxs]\n",
    "    for i, s in enumerate(samples):\n",
    "        print(\"Sample:\")\n",
    "        print(s.split(\"[PAD\")[0])\n",
    "        print(f\"Gold label: {'hateful' if labels[i] == 1 else 'non-hateful'}\")\n",
    "        print(f\"Before fine-tuning prob: {softmax(pred_before[i])[labels[i]]}\")\n",
    "        print(f\"After fine-tuning prob: {softmax(pred_after[i])[labels[i]]}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f6721",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = deltas_davidson[deltas_davidson.label==1].nlargest(5, \"delta\").index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8cef17",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_samples(results, data[1], \"davidson2017\", tokenizer, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55801d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = deltas_founta[deltas_founta.label==1].nlargest(5,  \"delta\").index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b49d999",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_samples(results, data[1], \"founta2018\", tokenizer, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40052cb6",
   "metadata": {},
   "source": [
    "## Largest degradations for non_hateful samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a695eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = deltas_davidson[deltas_davidson.label==0].nsmallest(5, \"delta\").index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f87e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_samples(results, data[1], \"davidson2017\", tokenizer, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454e3451",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = deltas_founta[deltas_founta.label==0].nsmallest(5, \"delta\").index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b93671",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_samples(results, data[1], \"founta2018\", tokenizer, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e904f39d",
   "metadata": {},
   "source": [
    "## Largest improvements for hateful-samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ceab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = deltas_davidson[deltas_davidson.label==1].nsmallest(5, \"delta\").index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271d7888",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_samples(results, data[1], \"davidson2017\", tokenizer, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92673f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = deltas_founta[deltas_founta.label==1].nsmallest(5, \"delta\").index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d85138",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_samples(results, data[1], \"founta2018\", tokenizer, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eedde0",
   "metadata": {},
   "source": [
    "## Largest improvements for non hateful-samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9355a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = deltas_davidson[deltas_davidson.label==0].nlargest(5, \"delta\").index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1e8183",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_samples(results, data[1], \"davidson2017\", tokenizer, idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efbb009",
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = deltas_founta[deltas_founta.label==0].nlargest(5, \"delta\").index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_samples(results, data[1], \"founta2018\", tokenizer, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91ca3af",
   "metadata": {},
   "source": [
    "## Manual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8fd579",
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_D = BertForSequenceClassification.from_pretrained(f\"./hatecheck-experiments/Models/BERT_davidson2017_weighted/Final\").cuda()\n",
    "BERT_F = BertForSequenceClassification.from_pretrained(f\"./hatecheck-experiments/Models/BERT_founta2018_weighted/Final\").cuda()\n",
    "BERT_D_R = BertForSequenceClassification.from_pretrained(f\"./hatecheck-experiments/Models/BERT_davidson2017_hatecheck_weighted/Final\").cuda()\n",
    "BERT_F_R = BertForSequenceClassification.from_pretrained(f\"./hatecheck-experiments/Models/BERT_founta2018_hatecheck_weighted/Final\").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1d1bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextClassificationPipeline\n",
    "\n",
    "def inspect_model(model, sentence):\n",
    "    pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=True, device=0)\n",
    "    # outputs a list of dicts like [[{'label': 'NEGATIVE', 'score': 0.0001223755971295759},  {'label': 'POSITIVE', 'score': 0.9998776316642761}]]\n",
    "    print(pipe(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ce741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [BERT_D, BERT_F, BERT_D_R, BERT_F_R]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a695dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[inspect_model(m, \"or a southern bitch like me who will blow a persons heart out of their back w / one shot!!!! \") for m in models]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "checking-hateCheck",
   "language": "python",
   "name": "checking-hatecheck"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
